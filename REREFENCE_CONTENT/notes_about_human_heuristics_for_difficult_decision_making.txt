"One of my favorite quotes from the article:   "

"I am firmly convinced that the human mind has done an extraordinarly useful job of optimizing in a highly uncertain and large-dimentional environment. ... I personally often look to how people 'heuristically' solve difficult problems, not for hints on how to form static heuristics for my own little agents to implement, but rather for guidance on how to simplify the objective problem my agents are attempting to solve (i.e. maximize) under high/fundamental uncertainty, low information, and many dimentions -- and in the absolute face of the 'no free lunch' exploration/exploitation tradeoff they inevitably [necessarily] over their reasonable short horizons (short horizons with respect to the amount of experience / time needed to solve the true optimal problem via, eg., DP or asynchronous DP)"
